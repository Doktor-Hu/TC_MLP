{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T13:51:09.111259Z",
     "start_time": "2021-03-03T13:51:05.262479Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "seed_value=66\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "python_random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "import sys\n",
    "sys.path.append('D:/Paper_1/Importance/Olden_for_Keras')\n",
    "from Olden_Keras import Olden\n",
    "sys.path.append('d:/Paper_1/Syntax/afunc')\n",
    "from plotaccdl import plot_history, plot_acc, plot_acc_no_colorbar, error_plot, train_preparation\n",
    "from MLP_acc import acc_report\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dropout, BatchNormalization, Activation, Input, Dense\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import scipy.stats as stats\n",
    "import glob\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T13:51:09.235015Z",
     "start_time": "2021-03-03T13:51:09.112258Z"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('D:/Paper_1/Data/allaws_dy_nnmatrix_dT0_snow_v2_train_no_NM_14_17.csv')\n",
    "test=pd.read_csv('D:/Paper_1/Data/allaws_dy_nnmatrix_dT0_snow_v2_test_no_NM_18.csv')\n",
    "\n",
    "train_labels_ori=np.asarray([float(i) for i in train['delta_melt']])\n",
    "test_labels_ori=np.asarray([float(i) for i in test['delta_melt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T13:51:10.977827Z",
     "start_time": "2021-03-03T13:51:10.956732Z"
    }
   },
   "outputs": [],
   "source": [
    "input_var=['albedo_0','delta_albedo','temp2m','shortwave_in','longwave_in','melt_0','meltflag','melt_TC','dayofyear']\n",
    "model_mode='Complete_Model'\n",
    "train_data,train_labels,test_data,test_labels=train_preparation(train,train_labels_ori,test,test_labels_ori,input_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T19:46:15.999422Z",
     "start_time": "2021-02-22T19:46:15.858151Z"
    },
    "code_folding": [
     0,
     7,
     14,
     21,
     28,
     42,
     63,
     84,
     121,
     158,
     180,
     202,
     224,
     252,
     266,
     280,
     294,
     308,
     333,
     358,
     378,
     403,
     428
    ]
   },
   "outputs": [],
   "source": [
    "def model_shallow():\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(12, activation='relu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "def model_shallow_48():\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(48, activation='relu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "def model_shallow_64():\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(64, activation='relu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.Adam(learning_rate=0.0003),metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "def model_shallow_48_l2():\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(48, activation='relu',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "def model_deep():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, activation='relu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "def model_deep_bn():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, activation='relu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='relu'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "def model_deep_bn2():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',input_shape = (train_data.shape[1],)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model   \n",
    "    \n",
    "def model_deep_bn2a():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model   \n",
    "\n",
    "def model_deep_bn2b():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(keras.layers.Dense(48, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model  \n",
    "    \n",
    "def model_deep_bn2c():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model  \n",
    "        \n",
    "def model_deep_bn2d():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(lr=0.0001,momentum=0.9,decay=1e-6, nesterov=True),metrics=['mae'])\n",
    "        return model \n",
    "    \n",
    "def model_deep_bn2e():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.999, epsilon=1e-08),metrics=['mae'])\n",
    "        return model     \n",
    "    \n",
    "def model_deep_bn3():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, input_shape = (train_data.shape[1],)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(keras.layers.Dense(12))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(keras.layers.Dense(12))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(keras.layers.Dense(12))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(keras.layers.Dense(12))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(keras.layers.Dense(12))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(keras.layers.Dense(12))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "    \n",
    "def model_deep_tanh():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "def model_deep_elu():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, activation='elu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(12, activation='elu'))\n",
    "        model.add(keras.layers.Dense(12, activation='elu'))\n",
    "        model.add(keras.layers.Dense(12, activation='elu'))\n",
    "        model.add(keras.layers.Dense(12, activation='elu'))\n",
    "        model.add(keras.layers.Dense(12, activation='elu'))\n",
    "        model.add(keras.layers.Dense(12, activation='elu'))\n",
    "        model.add(keras.layers.Dense(12, activation='elu'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "def model_deep_v2():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(24, activation='relu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(24, activation='relu'))\n",
    "        model.add(keras.layers.Dense(24, activation='relu'))\n",
    "        model.add(keras.layers.Dense(24, activation='relu'))\n",
    "        model.add(keras.layers.Dense(24, activation='relu'))\n",
    "        model.add(keras.layers.Dense(24, activation='relu'))\n",
    "        model.add(keras.layers.Dense(24, activation='relu'))\n",
    "        model.add(keras.layers.Dense(24, activation='relu'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "      \n",
    "def model_deep_v3():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='relu',input_shape = (train_data.shape[1],)))\n",
    "        model.add(keras.layers.Dense(48, activation='relu'))\n",
    "        model.add(keras.layers.Dense(48, activation='relu'))\n",
    "        model.add(keras.layers.Dense(48, activation='relu'))\n",
    "        model.add(keras.layers.Dense(48, activation='relu'))\n",
    "        model.add(keras.layers.Dense(48, activation='relu'))\n",
    "        model.add(keras.layers.Dense(48, activation='relu'))\n",
    "        model.add(keras.layers.Dense(48, activation='relu'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "    \n",
    "def model_deep_large():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='elu',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='elu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "    \n",
    "def model_deep_large_tanh():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "\n",
    "def model_deep_large_tanh2():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(48, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(48, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "    \n",
    "def model_deep_large_tanh3():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))     \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))        \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))     \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))      \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(12, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "\n",
    "def model_deep_large_tanh4():\n",
    "        model = keras.Sequential()     \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',input_shape = (train_data.shape[1],),kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))     \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))        \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))     \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))      \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))       \n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(60, activation='tanh',kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse',optimizer = keras.optimizers.SGD(learning_rate=0.0001),metrics=['mae'])\n",
    "        return model \n",
    "    \n",
    "def model_deep_large_tanh4_res():\n",
    "    \n",
    "        model = keras.Sequential()  \n",
    "        \n",
    "        a0 = Input(shape=(train_data.shape[1],))\n",
    "        \n",
    "        a1 = Dense(64,kernel_initializer=keras.initializers.glorot_uniform(seed=1))(a0)\n",
    "        a1a= Activation('tanh')(a1)\n",
    "        \n",
    "#----------------------------------------------------------------------           \n",
    "        a2 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a1a)\n",
    "        a2a= Activation('tanh')(a2)\n",
    "        a2d = Dropout(0.1)(a2a)\n",
    "#----------------------------------------------------------------------           \n",
    "        \n",
    "        a3 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a2d)\n",
    "        a3a= Activation('tanh')(a3)\n",
    "        \n",
    "        a4 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a3a+a1a) #SC1\n",
    "        a4a= Activation('tanh')(a4)\n",
    "        \n",
    "        a5 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a4a)\n",
    "        a5a= Activation('tanh')(a5)\n",
    "\n",
    "#----------------------------------------------------------------------   \n",
    "        a6 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a5a)\n",
    "        a6a= Activation('tanh')(a6)\n",
    "        a6d = Dropout(0.1)(a6a)\n",
    "#----------------------------------------------------------------------        \n",
    "\n",
    "        a7 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a6d)\n",
    "        a7a= Activation('tanh')(a7)\n",
    "\n",
    "        a8 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a7a+a4a) #SC2\n",
    "        a8a= Activation('tanh')(a8)\n",
    "        \n",
    "        a9 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a8a)\n",
    "        a9a= Activation('tanh')(a9)\n",
    "\n",
    "#----------------------------------------------------------------------           \n",
    "        a10 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a9a)\n",
    "        a10a= Activation('tanh')(a10)\n",
    "        a10d = Dropout(0.1)(a10a)\n",
    "#----------------------------------------------------------------------   \n",
    "        \n",
    "        a11 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a10d)\n",
    "        a11a= Activation('tanh')(a11)\n",
    "\n",
    "        a12 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a11a+a8a) #SC3\n",
    "        a12a= Activation('tanh')(a12)\n",
    "        \n",
    "        a13 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a12a)\n",
    "        a13a= Activation('tanh')(a13)\n",
    "\n",
    "#----------------------------------------------------------------------           \n",
    "        a14 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a13a)\n",
    "        a14a= Activation('tanh')(a14)\n",
    "        a14d = Dropout(0.1)(a14a)        \n",
    "#----------------------------------------------------------------------   \n",
    "\n",
    "        a15 = Dense(64,kernel_regularizer=regularizers.l2(0.001))(a14d)\n",
    "        a15a= Activation('tanh')(a15)\n",
    "\n",
    "        \n",
    "        a16 = Dense(1)(a15a)\n",
    "        \n",
    "        model = Model(inputs=a0, outputs=a16)\n",
    "        model.compile(loss='mean_squared_error',optimizer = keras.optimizers.Adam(learning_rate=0.0003),metrics=['mean_squared_error','mae'])\n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T19:46:20.702842Z",
     "start_time": "2021-02-22T19:46:18.448653Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list={\"_shallow\": model_shallow(),\n",
    "            \"_shallow_48\": model_shallow_48(),\n",
    "           \"_shallow_48_l2\": model_shallow_48_l2(),\n",
    "           \"_deep\": model_deep(),\n",
    "           \"_deep_bn\": model_deep_bn(),\n",
    "           \"_deep_bn2\":model_deep_bn2(),\n",
    "           \"_deep_bn2a\":model_deep_bn2a(),\n",
    "           \"_deep_bn2b\":model_deep_bn2b(),\n",
    "           \"_deep_bn2c\":model_deep_bn2c(),\n",
    "           \"_deep_bn2d\":model_deep_bn2d(),\n",
    "           \"_deep_bn2e\":model_deep_bn2e(),\n",
    "           \"_deep_bn3\":model_deep_bn3(),\n",
    "           \"_deep_tanh\":model_deep_tanh(),\n",
    "           \"_deep_elu\":model_deep_elu(),\n",
    "           \"_deep_v2\":model_deep_v2(),\n",
    "           \"_deep_v3\":model_deep_v3(),\n",
    "           \"_deep_large\":model_deep_large(),\n",
    "           \"_deep_large_tanh\":model_deep_large_tanh(),\n",
    "           \"_deep_large_tanh2\":model_deep_large_tanh2(),\n",
    "           \"_deep_large_tanh3\":model_deep_large_tanh3(),\n",
    "           \"_deep_large_tanh4\":model_deep_large_tanh4(),\n",
    "           \"_deep_large_tanh4_res\":model_deep_large_tanh4_res()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-22T19:46:23.176Z"
    }
   },
   "outputs": [],
   "source": [
    "for mode_act in model_list.keys():\n",
    "    print(mode_act)\n",
    "    model=model_list[mode_act]\n",
    "    model.summary()\n",
    "\n",
    "    EPOCHS = 5000\n",
    "\n",
    "    class PrintDot(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs):\n",
    "            if epoch % 100 ==0 : print(\"\") \n",
    "            print('=',end='')\n",
    "        \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,min_delta=0.0001,mode='min')\n",
    "\n",
    "    history = model.fit(train_data, train_labels, epochs=EPOCHS,\n",
    "                        validation_split=0.3, verbose=1, \n",
    "                        callbacks=[early_stop, PrintDot()],batch_size=4096)   \n",
    "    \n",
    "    plot_history(history,'D:/Paper_1/Large_Model/MLP/training_process_'+model_mode+mode_act+'.png')\n",
    "\n",
    "    model_pre=model.predict(test_data)\n",
    "    x = model_pre.flatten()\n",
    "    plot_acc(x,test_labels,model_mode,'D:/Paper_1/Large_Model/MLP/accuracy_'+model_mode+mode_act+'.png')\n",
    "\n",
    "    error_plot(x,test_labels,model_mode,'D:/Paper_1/Large_Model/MLP/error_'+model_mode+mode_act+'.png')\n",
    "    \n",
    "    model.save('D:/Paper_1/Large_Model/MLP/MLP_'+model_mode+mode_act+'.h5')\n",
    "    \n",
    "    K.clear_session()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T13:51:27.525901Z",
     "start_time": "2021-03-03T13:51:27.517397Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def acc_report(model_name,train,train_labels_ori,test,test_labels_ori,input_variables):\n",
    "    \n",
    "    model=load_model(model_name)\n",
    "    train_data,train_labels,test_data,test_labels=train_preparation(train,train_labels_ori,test,test_labels_ori,input_variables)\n",
    "    \n",
    "    x1 = model.predict(train_data).flatten()\n",
    "    y1= train_labels\n",
    "    \n",
    "    x2=model.predict(test_data).flatten()\n",
    "    y2=test_labels\n",
    "    \n",
    "    \n",
    "    train_rmse=sqrt(mean_squared_error(x1,y1))\n",
    "    train_mae=np.sum(abs(x1-y1))/len(x1)\n",
    "    train_r2=stats.pearsonr(x1, y1)[0]**2 \n",
    "    \n",
    "    test_rmse=sqrt(mean_squared_error(x2,y2))\n",
    "    test_mae=np.sum(abs(x2-y2))/len(x2)\n",
    "    test_r2=stats.pearsonr(x2, y2)[0]**2\n",
    "    \n",
    "    diff_rmse=test_rmse-train_rmse\n",
    "    diff_mae=test_mae-train_mae\n",
    "    diff_r2=train_r2-test_r2\n",
    "    \n",
    "    \n",
    "    print(model_name)\n",
    "    print(' ')\n",
    "    print('Training')\n",
    "    print('rmse: '+str(sqrt(mean_squared_error(x1,y1)))) \n",
    "    print('mae: ' +str(np.sum(abs(x1-y1))/len(x1)))\n",
    "    print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x1, y1)[0]**2,5)))\n",
    "          \n",
    "    print('Testing')\n",
    "    print('rmse: '+str(sqrt(mean_squared_error(x2,y2)))) \n",
    "    print('mae: ' +str(np.sum(abs(x2-y2))/len(x2)))\n",
    "    print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x2, y2)[0]**2,5)))\n",
    "    \n",
    "    print('Difference')\n",
    "    print('drmse: '+str(sqrt(mean_squared_error(x2,y2))-(sqrt(mean_squared_error(x1,y1))))) \n",
    "    print('dmae: ' +str(np.sum(abs(x2-y2))/len(x2)-(np.sum(abs(x1-y1))/len(x1))))\n",
    "    print(\"d$\\mathregular{R^2}$=\"+str((round(stats.pearsonr(x1, y1)[0]**2,5))-round(stats.pearsonr(x2, y2)[0]**2,5)))\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    return train_rmse, train_mae, train_r2, test_rmse, test_mae, test_r2, diff_rmse, diff_mae, diff_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:07:36.219503Z",
     "start_time": "2021-03-03T14:07:35.081489Z"
    }
   },
   "outputs": [],
   "source": [
    "model=load_model(('D:/Paper_1/Large_Model/MLP/MLP_Complete_Model_deep_large_tanh4_res.h5'))\n",
    "train_data,train_labels,test_data,test_labels=train_preparation(train,train_labels_ori,test,test_labels_ori,input_var)\n",
    "    \n",
    "x1 = model.predict(train_data).flatten()\n",
    "y1= train_labels\n",
    "    \n",
    "x2=model.predict(test_data).flatten()\n",
    "y2=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:08:16.559022Z",
     "start_time": "2021-03-03T14:08:16.553965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9478760104201338"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(x2,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:09:32.727270Z",
     "start_time": "2021-03-03T14:09:32.712247Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('D:/Paper_1/Large_Model/MLP/Predicted_AWS18', x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:05:13.706387Z",
     "start_time": "2021-02-22T23:04:52.133195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.1214599289813312\n",
      "mae: 0.4487187810488209\n",
      "$\\mathregular{R^2}$=0.93393\n",
      "Testing\n",
      "rmse: 1.0469399184658252\n",
      "mae: 0.43603326615207727\n",
      "$\\mathregular{R^2}$=0.94324\n",
      "Difference\n",
      "drmse: -0.07452001051550594\n",
      "dmae: -0.012685514896743633\n",
      "d$\\mathregular{R^2}$=-0.00930999999999993\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0155520769173032\n",
      "mae: 0.4673968054729388\n",
      "$\\mathregular{R^2}$=0.94579\n",
      "Testing\n",
      "rmse: 1.1595434119271668\n",
      "mae: 0.5470878995769687\n",
      "$\\mathregular{R^2}$=0.93085\n",
      "Difference\n",
      "drmse: 0.1439913350098636\n",
      "dmae: 0.07969109410402986\n",
      "d$\\mathregular{R^2}$=0.014940000000000064\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn2.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0036826504404168\n",
      "mae: 0.43875473105941587\n",
      "$\\mathregular{R^2}$=0.94776\n",
      "Testing\n",
      "rmse: 1.0728136125526853\n",
      "mae: 0.5087159046659121\n",
      "$\\mathregular{R^2}$=0.94162\n",
      "Difference\n",
      "drmse: 0.06913096211226843\n",
      "dmae: 0.06996117360649623\n",
      "d$\\mathregular{R^2}$=0.006140000000000034\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn2a.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.1209500021398437\n",
      "mae: 0.5173145483700619\n",
      "$\\mathregular{R^2}$=0.93527\n",
      "Testing\n",
      "rmse: 1.356366542285818\n",
      "mae: 0.6104918076966694\n",
      "$\\mathregular{R^2}$=0.906\n",
      "Difference\n",
      "drmse: 0.23541654014597424\n",
      "dmae: 0.09317725932660759\n",
      "d$\\mathregular{R^2}$=0.029270000000000018\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn2b.h5\n",
      " \n",
      "Training\n",
      "rmse: 0.9363393143867983\n",
      "mae: 0.48212504464836786\n",
      "$\\mathregular{R^2}$=0.95457\n",
      "Testing\n",
      "rmse: 1.2678659927369609\n",
      "mae: 0.6815830552978415\n",
      "$\\mathregular{R^2}$=0.91772\n",
      "Difference\n",
      "drmse: 0.3315266783501626\n",
      "dmae: 0.1994580106494736\n",
      "d$\\mathregular{R^2}$=0.03685000000000005\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn2c.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0671345300432427\n",
      "mae: 0.5166480916636128\n",
      "$\\mathregular{R^2}$=0.94196\n",
      "Testing\n",
      "rmse: 1.138108866630667\n",
      "mae: 0.5653070640268453\n",
      "$\\mathregular{R^2}$=0.93416\n",
      "Difference\n",
      "drmse: 0.07097433658742425\n",
      "dmae: 0.04865897236323247\n",
      "d$\\mathregular{R^2}$=0.007800000000000029\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn2d.h5\n",
      " \n",
      "Training\n",
      "rmse: 0.9100360102414806\n",
      "mae: 0.41688688777269556\n",
      "$\\mathregular{R^2}$=0.95738\n",
      "Testing\n",
      "rmse: 0.9370471438982694\n",
      "mae: 0.4465348147835349\n",
      "$\\mathregular{R^2}$=0.9557\n",
      "Difference\n",
      "drmse: 0.027011133656788755\n",
      "dmae: 0.029647927010839348\n",
      "d$\\mathregular{R^2}$=0.0016800000000000148\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn2e.h5\n",
      " \n",
      "Training\n",
      "rmse: 0.8787653696824517\n",
      "mae: 0.3397859736946646\n",
      "$\\mathregular{R^2}$=0.95951\n",
      "Testing\n",
      "rmse: 0.984635351722959\n",
      "mae: 0.3930790424674873\n",
      "$\\mathregular{R^2}$=0.94957\n",
      "Difference\n",
      "drmse: 0.10586998204050735\n",
      "dmae: 0.053293068772822694\n",
      "d$\\mathregular{R^2}$=0.009939999999999949\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_bn3.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0452671735076624\n",
      "mae: 0.49733812011277767\n",
      "$\\mathregular{R^2}$=0.94357\n",
      "Testing\n",
      "rmse: 1.1107436804078865\n",
      "mae: 0.5690583010378046\n",
      "$\\mathregular{R^2}$=0.93837\n",
      "Difference\n",
      "drmse: 0.06547650690022411\n",
      "dmae: 0.07172018092502697\n",
      "d$\\mathregular{R^2}$=0.005199999999999982\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_elu.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.034435592565921\n",
      "mae: 0.4576731601020735\n",
      "$\\mathregular{R^2}$=0.94375\n",
      "Testing\n",
      "rmse: 1.0039993182613824\n",
      "mae: 0.47825552384908127\n",
      "$\\mathregular{R^2}$=0.94761\n",
      "Difference\n",
      "drmse: -0.030436274304538546\n",
      "dmae: 0.02058236374700778\n",
      "d$\\mathregular{R^2}$=-0.0038599999999999746\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_large.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0128868100924893\n",
      "mae: 0.42609924660152226\n",
      "$\\mathregular{R^2}$=0.9461\n",
      "Testing\n",
      "rmse: 1.079609280224063\n",
      "mae: 0.48057788155801723\n",
      "$\\mathregular{R^2}$=0.93988\n",
      "Difference\n",
      "drmse: 0.06672247013157384\n",
      "dmae: 0.054478634956494965\n",
      "d$\\mathregular{R^2}$=0.006220000000000003\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_large_tanh.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.1804159781597334\n",
      "mae: 0.5339963094792441\n",
      "$\\mathregular{R^2}$=0.92677\n",
      "Testing\n",
      "rmse: 1.21279377080447\n",
      "mae: 0.5518927903685847\n",
      "$\\mathregular{R^2}$=0.92399\n",
      "Difference\n",
      "drmse: 0.032377792644736614\n",
      "dmae: 0.017896480889340594\n",
      "d$\\mathregular{R^2}$=0.0027800000000000047\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_large_tanh2.h5\n",
      " \n",
      "Training\n",
      "rmse: 0.993643856929837\n",
      "mae: 0.46119319973242223\n",
      "$\\mathregular{R^2}$=0.94885\n",
      "Testing\n",
      "rmse: 1.0031613473515502\n",
      "mae: 0.49212699045080904\n",
      "$\\mathregular{R^2}$=0.9495\n",
      "Difference\n",
      "drmse: 0.009517490421713126\n",
      "dmae: 0.03093379071838681\n",
      "d$\\mathregular{R^2}$=-0.0006500000000000394\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_large_tanh3.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.3674887735688182\n",
      "mae: 0.5858999611737622\n",
      "$\\mathregular{R^2}$=0.90318\n",
      "Testing\n",
      "rmse: 1.3310410391788667\n",
      "mae: 0.575193403716467\n",
      "$\\mathregular{R^2}$=0.91159\n",
      "Difference\n",
      "drmse: -0.036447734389951414\n",
      "dmae: -0.010706557457295207\n",
      "d$\\mathregular{R^2}$=-0.008410000000000029\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_large_tanh4.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.100371388219779\n",
      "mae: 0.4762261440110914\n",
      "$\\mathregular{R^2}$=0.93638\n",
      "Testing\n",
      "rmse: 1.136060513370348\n",
      "mae: 0.49053483416018984\n",
      "$\\mathregular{R^2}$=0.93288\n",
      "Difference\n",
      "drmse: 0.0356891251505691\n",
      "dmae: 0.014308690149098413\n",
      "d$\\mathregular{R^2}$=0.0034999999999999476\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_large_tanh4_res.h5\n",
      " \n",
      "Training\n",
      "rmse: 0.7722184877362351\n",
      "mae: 0.33458813507756247\n",
      "$\\mathregular{R^2}$=0.9689\n",
      "Testing\n",
      "rmse: 0.9478760104201338\n",
      "mae: 0.42472405615009456\n",
      "$\\mathregular{R^2}$=0.95387\n",
      "Difference\n",
      "drmse: 0.17565752268389867\n",
      "dmae: 0.0901359210725321\n",
      "d$\\mathregular{R^2}$=0.015029999999999988\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_tanh.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0263770376126164\n",
      "mae: 0.4339292229780306\n",
      "$\\mathregular{R^2}$=0.94526\n",
      "Testing\n",
      "rmse: 1.196297487752851\n",
      "mae: 0.5016888880054855\n",
      "$\\mathregular{R^2}$=0.92644\n",
      "Difference\n",
      "drmse: 0.1699204501402345\n",
      "dmae: 0.0677596650274549\n",
      "d$\\mathregular{R^2}$=0.018819999999999948\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_v2.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0325773987562146\n",
      "mae: 0.42069612499091674\n",
      "$\\mathregular{R^2}$=0.94408\n",
      "Testing\n",
      "rmse: 1.0357040516405782\n",
      "mae: 0.44732667309265534\n",
      "$\\mathregular{R^2}$=0.94446\n",
      "Difference\n",
      "drmse: 0.0031266528843636454\n",
      "dmae: 0.026630548101738594\n",
      "d$\\mathregular{R^2}$=-0.00037999999999993594\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_deep_v3.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.0177515280549048\n",
      "mae: 0.41198750235293025\n",
      "$\\mathregular{R^2}$=0.94555\n",
      "Testing\n",
      "rmse: 1.0047949676658006\n",
      "mae: 0.4403582784526299\n",
      "$\\mathregular{R^2}$=0.94787\n",
      "Difference\n",
      "drmse: -0.0129565603891042\n",
      "dmae: 0.02837077609969968\n",
      "d$\\mathregular{R^2}$=-0.0023199999999999887\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_shallow.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.2660430498613668\n",
      "mae: 0.6660231147832891\n",
      "$\\mathregular{R^2}$=0.91582\n",
      "Testing\n",
      "rmse: 1.2728980761644983\n",
      "mae: 0.6867153575524748\n",
      "$\\mathregular{R^2}$=0.91613\n",
      "Difference\n",
      "drmse: 0.006855026303131506\n",
      "dmae: 0.020692242769185687\n",
      "d$\\mathregular{R^2}$=-0.00031000000000003247\n",
      "------------------------------------------------------------\n",
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_shallow_48.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.2420937497366102\n",
      "mae: 0.6526189709146176\n",
      "$\\mathregular{R^2}$=0.91905\n",
      "Testing\n",
      "rmse: 1.3151075615957297\n",
      "mae: 0.7157584297448115\n",
      "$\\mathregular{R^2}$=0.91126\n",
      "Difference\n",
      "drmse: 0.07301381185911948\n",
      "dmae: 0.0631394588301939\n",
      "d$\\mathregular{R^2}$=0.007790000000000075\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Paper_1/Large_Model/MLP\\MLP_Complete_Model_shallow_48_l2.h5\n",
      " \n",
      "Training\n",
      "rmse: 1.247394201211747\n",
      "mae: 0.6685017468877537\n",
      "$\\mathregular{R^2}$=0.91835\n",
      "Testing\n",
      "rmse: 1.3675581060659787\n",
      "mae: 0.7452453559292869\n",
      "$\\mathregular{R^2}$=0.90487\n",
      "Difference\n",
      "drmse: 0.12016390485423178\n",
      "dmae: 0.07674360904153321\n",
      "d$\\mathregular{R^2}$=0.013480000000000047\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#models=glob.glob('D:/Paper_1/Light_Model_V2/REF17_DOY/*.h5')\n",
    "models=glob.glob('D:/Paper_1/Large_Model/MLP/*.h5')\n",
    "acc_stat=pd.DataFrame(-9999,index=range(len(models)),columns=[\"Model_ID\",\"Train_RMSE\",\"Train_MAE\",\"Train_R2\",\"Test_RMSE\",\n",
    "                                                              \"Test_MAE\",\"Test_R2\",\"Diff_RMSE\",\"Diff_MAE\",\n",
    "                                                              \"#Hidden_Layer\",\"#Neuron\",\"Activtion\",\"Regularizer\",\"Optimizer\",\"BN\"])\n",
    "\n",
    "i=0\n",
    "for model_name in models:\n",
    "    \n",
    "    train_rmse, train_mae, train_r2, test_rmse, test_mae, test_r2, diff_rmse, diff_mae, diff_r2=acc_report(model_name,train,train_labels_ori,test,test_labels_ori,input_var)\n",
    "    \n",
    "    acc_stat.iloc[i,0]=os.path.basename(model_name)\n",
    "    acc_stat.iloc[i,1]=train_rmse\n",
    "    acc_stat.iloc[i,2]=train_mae\n",
    "    acc_stat.iloc[i,3]=train_r2\n",
    "    acc_stat.iloc[i,4]=test_rmse\n",
    "    acc_stat.iloc[i,5]=test_mae\n",
    "    acc_stat.iloc[i,6]=test_r2\n",
    "    acc_stat.iloc[i,7]=diff_rmse\n",
    "    acc_stat.iloc[i,8]=diff_mae\n",
    "    \n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:05:31.075034Z",
     "start_time": "2021-02-22T23:05:31.004925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_ID</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Train_MAE</th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>Test_MAE</th>\n",
       "      <th>Test_R2</th>\n",
       "      <th>Diff_RMSE</th>\n",
       "      <th>Diff_MAE</th>\n",
       "      <th>#Hidden_Layer</th>\n",
       "      <th>#Neuron</th>\n",
       "      <th>Activtion</th>\n",
       "      <th>Regularizer</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>BN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP_Complete_Model_deep.h5</td>\n",
       "      <td>1.121460</td>\n",
       "      <td>0.448719</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>1.046940</td>\n",
       "      <td>0.436033</td>\n",
       "      <td>0.943237</td>\n",
       "      <td>-0.074520</td>\n",
       "      <td>-0.012686</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP_Complete_Model_deep_bn.h5</td>\n",
       "      <td>1.015552</td>\n",
       "      <td>0.467397</td>\n",
       "      <td>0.945789</td>\n",
       "      <td>1.159543</td>\n",
       "      <td>0.547088</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.143991</td>\n",
       "      <td>0.079691</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP_Complete_Model_deep_bn2.h5</td>\n",
       "      <td>1.003683</td>\n",
       "      <td>0.438755</td>\n",
       "      <td>0.947765</td>\n",
       "      <td>1.072814</td>\n",
       "      <td>0.508716</td>\n",
       "      <td>0.941618</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>0.069961</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP_Complete_Model_deep_bn2a.h5</td>\n",
       "      <td>1.120950</td>\n",
       "      <td>0.517315</td>\n",
       "      <td>0.935274</td>\n",
       "      <td>1.356367</td>\n",
       "      <td>0.610492</td>\n",
       "      <td>0.905995</td>\n",
       "      <td>0.235417</td>\n",
       "      <td>0.093177</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP_Complete_Model_deep_bn2b.h5</td>\n",
       "      <td>0.936339</td>\n",
       "      <td>0.482125</td>\n",
       "      <td>0.954565</td>\n",
       "      <td>1.267866</td>\n",
       "      <td>0.681583</td>\n",
       "      <td>0.917721</td>\n",
       "      <td>0.331527</td>\n",
       "      <td>0.199458</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP_Complete_Model_deep_bn2c.h5</td>\n",
       "      <td>1.067135</td>\n",
       "      <td>0.516648</td>\n",
       "      <td>0.941958</td>\n",
       "      <td>1.138109</td>\n",
       "      <td>0.565307</td>\n",
       "      <td>0.934161</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.048659</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP_Complete_Model_deep_bn2d.h5</td>\n",
       "      <td>0.910036</td>\n",
       "      <td>0.416887</td>\n",
       "      <td>0.957383</td>\n",
       "      <td>0.937047</td>\n",
       "      <td>0.446535</td>\n",
       "      <td>0.955702</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>0.029648</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP_Complete_Model_deep_bn2e.h5</td>\n",
       "      <td>0.878765</td>\n",
       "      <td>0.339786</td>\n",
       "      <td>0.959515</td>\n",
       "      <td>0.984635</td>\n",
       "      <td>0.393079</td>\n",
       "      <td>0.949572</td>\n",
       "      <td>0.105870</td>\n",
       "      <td>0.053293</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLP_Complete_Model_deep_bn3.h5</td>\n",
       "      <td>1.045267</td>\n",
       "      <td>0.497338</td>\n",
       "      <td>0.943573</td>\n",
       "      <td>1.110744</td>\n",
       "      <td>0.569058</td>\n",
       "      <td>0.938374</td>\n",
       "      <td>0.065477</td>\n",
       "      <td>0.071720</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP_Complete_Model_deep_elu.h5</td>\n",
       "      <td>1.034436</td>\n",
       "      <td>0.457673</td>\n",
       "      <td>0.943748</td>\n",
       "      <td>1.003999</td>\n",
       "      <td>0.478256</td>\n",
       "      <td>0.947610</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP_Complete_Model_deep_large.h5</td>\n",
       "      <td>1.012887</td>\n",
       "      <td>0.426099</td>\n",
       "      <td>0.946101</td>\n",
       "      <td>1.079609</td>\n",
       "      <td>0.480578</td>\n",
       "      <td>0.939883</td>\n",
       "      <td>0.066722</td>\n",
       "      <td>0.054479</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP_Complete_Model_deep_large_tanh.h5</td>\n",
       "      <td>1.180416</td>\n",
       "      <td>0.533996</td>\n",
       "      <td>0.926766</td>\n",
       "      <td>1.212794</td>\n",
       "      <td>0.551893</td>\n",
       "      <td>0.923992</td>\n",
       "      <td>0.032378</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLP_Complete_Model_deep_large_tanh2.h5</td>\n",
       "      <td>0.993644</td>\n",
       "      <td>0.461193</td>\n",
       "      <td>0.948852</td>\n",
       "      <td>1.003161</td>\n",
       "      <td>0.492127</td>\n",
       "      <td>0.949502</td>\n",
       "      <td>0.009517</td>\n",
       "      <td>0.030934</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLP_Complete_Model_deep_large_tanh3.h5</td>\n",
       "      <td>1.367489</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.903180</td>\n",
       "      <td>1.331041</td>\n",
       "      <td>0.575193</td>\n",
       "      <td>0.911594</td>\n",
       "      <td>-0.036448</td>\n",
       "      <td>-0.010707</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP_Complete_Model_deep_large_tanh4.h5</td>\n",
       "      <td>1.100371</td>\n",
       "      <td>0.476226</td>\n",
       "      <td>0.936382</td>\n",
       "      <td>1.136061</td>\n",
       "      <td>0.490535</td>\n",
       "      <td>0.932882</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.014309</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP_Complete_Model_deep_large_tanh4_res.h5</td>\n",
       "      <td>0.772218</td>\n",
       "      <td>0.334588</td>\n",
       "      <td>0.968902</td>\n",
       "      <td>0.947876</td>\n",
       "      <td>0.424724</td>\n",
       "      <td>0.953866</td>\n",
       "      <td>0.175658</td>\n",
       "      <td>0.090136</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLP_Complete_Model_deep_tanh.h5</td>\n",
       "      <td>1.026377</td>\n",
       "      <td>0.433929</td>\n",
       "      <td>0.945257</td>\n",
       "      <td>1.196297</td>\n",
       "      <td>0.501689</td>\n",
       "      <td>0.926437</td>\n",
       "      <td>0.169920</td>\n",
       "      <td>0.067760</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLP_Complete_Model_deep_v2.h5</td>\n",
       "      <td>1.032577</td>\n",
       "      <td>0.420696</td>\n",
       "      <td>0.944078</td>\n",
       "      <td>1.035704</td>\n",
       "      <td>0.447327</td>\n",
       "      <td>0.944463</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP_Complete_Model_deep_v3.h5</td>\n",
       "      <td>1.017752</td>\n",
       "      <td>0.411988</td>\n",
       "      <td>0.945555</td>\n",
       "      <td>1.004795</td>\n",
       "      <td>0.440358</td>\n",
       "      <td>0.947872</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>0.028371</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP_Complete_Model_shallow.h5</td>\n",
       "      <td>1.266043</td>\n",
       "      <td>0.666023</td>\n",
       "      <td>0.915822</td>\n",
       "      <td>1.272898</td>\n",
       "      <td>0.686715</td>\n",
       "      <td>0.916128</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLP_Complete_Model_shallow_48.h5</td>\n",
       "      <td>1.242094</td>\n",
       "      <td>0.652619</td>\n",
       "      <td>0.919053</td>\n",
       "      <td>1.315108</td>\n",
       "      <td>0.715758</td>\n",
       "      <td>0.911264</td>\n",
       "      <td>0.073014</td>\n",
       "      <td>0.063139</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLP_Complete_Model_shallow_48_l2.h5</td>\n",
       "      <td>1.247394</td>\n",
       "      <td>0.668502</td>\n",
       "      <td>0.918347</td>\n",
       "      <td>1.367558</td>\n",
       "      <td>0.745245</td>\n",
       "      <td>0.904875</td>\n",
       "      <td>0.120164</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model_ID  Train_RMSE  Train_MAE  \\\n",
       "0                   MLP_Complete_Model_deep.h5    1.121460   0.448719   \n",
       "1                MLP_Complete_Model_deep_bn.h5    1.015552   0.467397   \n",
       "2               MLP_Complete_Model_deep_bn2.h5    1.003683   0.438755   \n",
       "3              MLP_Complete_Model_deep_bn2a.h5    1.120950   0.517315   \n",
       "4              MLP_Complete_Model_deep_bn2b.h5    0.936339   0.482125   \n",
       "5              MLP_Complete_Model_deep_bn2c.h5    1.067135   0.516648   \n",
       "6              MLP_Complete_Model_deep_bn2d.h5    0.910036   0.416887   \n",
       "7              MLP_Complete_Model_deep_bn2e.h5    0.878765   0.339786   \n",
       "8               MLP_Complete_Model_deep_bn3.h5    1.045267   0.497338   \n",
       "9               MLP_Complete_Model_deep_elu.h5    1.034436   0.457673   \n",
       "10            MLP_Complete_Model_deep_large.h5    1.012887   0.426099   \n",
       "11       MLP_Complete_Model_deep_large_tanh.h5    1.180416   0.533996   \n",
       "12      MLP_Complete_Model_deep_large_tanh2.h5    0.993644   0.461193   \n",
       "13      MLP_Complete_Model_deep_large_tanh3.h5    1.367489   0.585900   \n",
       "14      MLP_Complete_Model_deep_large_tanh4.h5    1.100371   0.476226   \n",
       "15  MLP_Complete_Model_deep_large_tanh4_res.h5    0.772218   0.334588   \n",
       "16             MLP_Complete_Model_deep_tanh.h5    1.026377   0.433929   \n",
       "17               MLP_Complete_Model_deep_v2.h5    1.032577   0.420696   \n",
       "18               MLP_Complete_Model_deep_v3.h5    1.017752   0.411988   \n",
       "19               MLP_Complete_Model_shallow.h5    1.266043   0.666023   \n",
       "20            MLP_Complete_Model_shallow_48.h5    1.242094   0.652619   \n",
       "21         MLP_Complete_Model_shallow_48_l2.h5    1.247394   0.668502   \n",
       "\n",
       "    Train_R2  Test_RMSE  Test_MAE   Test_R2  Diff_RMSE  Diff_MAE  \\\n",
       "0   0.933934   1.046940  0.436033  0.943237  -0.074520 -0.012686   \n",
       "1   0.945789   1.159543  0.547088  0.930851   0.143991  0.079691   \n",
       "2   0.947765   1.072814  0.508716  0.941618   0.069131  0.069961   \n",
       "3   0.935274   1.356367  0.610492  0.905995   0.235417  0.093177   \n",
       "4   0.954565   1.267866  0.681583  0.917721   0.331527  0.199458   \n",
       "5   0.941958   1.138109  0.565307  0.934161   0.070974  0.048659   \n",
       "6   0.957383   0.937047  0.446535  0.955702   0.027011  0.029648   \n",
       "7   0.959515   0.984635  0.393079  0.949572   0.105870  0.053293   \n",
       "8   0.943573   1.110744  0.569058  0.938374   0.065477  0.071720   \n",
       "9   0.943748   1.003999  0.478256  0.947610  -0.030436  0.020582   \n",
       "10  0.946101   1.079609  0.480578  0.939883   0.066722  0.054479   \n",
       "11  0.926766   1.212794  0.551893  0.923992   0.032378  0.017896   \n",
       "12  0.948852   1.003161  0.492127  0.949502   0.009517  0.030934   \n",
       "13  0.903180   1.331041  0.575193  0.911594  -0.036448 -0.010707   \n",
       "14  0.936382   1.136061  0.490535  0.932882   0.035689  0.014309   \n",
       "15  0.968902   0.947876  0.424724  0.953866   0.175658  0.090136   \n",
       "16  0.945257   1.196297  0.501689  0.926437   0.169920  0.067760   \n",
       "17  0.944078   1.035704  0.447327  0.944463   0.003127  0.026631   \n",
       "18  0.945555   1.004795  0.440358  0.947872  -0.012957  0.028371   \n",
       "19  0.915822   1.272898  0.686715  0.916128   0.006855  0.020692   \n",
       "20  0.919053   1.315108  0.715758  0.911264   0.073014  0.063139   \n",
       "21  0.918347   1.367558  0.745245  0.904875   0.120164  0.076744   \n",
       "\n",
       "    #Hidden_Layer  #Neuron  Activtion  Regularizer  Optimizer    BN  \n",
       "0           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "1           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "2           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "3           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "4           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "5           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "6           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "7           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "8           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "9           -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "10          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "11          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "12          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "13          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "14          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "15          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "16          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "17          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "18          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "19          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "20          -9999    -9999      -9999        -9999      -9999 -9999  \n",
       "21          -9999    -9999      -9999        -9999      -9999 -9999  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:05:59.063140Z",
     "start_time": "2021-02-22T23:05:59.045120Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_stat.to_csv('D:/Paper_1/Large_Model/MLP/REF18_Complete_acc_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:06:03.526476Z",
     "start_time": "2021-02-22T23:06:02.829444Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:06:24.290103Z",
     "start_time": "2021-02-22T23:06:24.247101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Paper_1/Large_Model/ML/LM_no_NM.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LM\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X = train_data,y = train_labels)\n",
    "joblib.dump(lm_model, 'D:/Paper_1/Large_Model/ML/LM_no_NM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:06:26.860592Z",
     "start_time": "2021-02-22T23:06:26.837775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "rmse: 3.0443983281187297\n",
      "mae: 2.1869896235769057\n",
      "$\\mathregular{R^2}$=0.51268\n",
      "Testing\n",
      "rmse: 3.191539630964821\n",
      "mae: 2.3498126849678274\n",
      "$\\mathregular{R^2}$=0.4796\n"
     ]
    }
   ],
   "source": [
    "model=lm_model\n",
    "x1 = model.predict(train_data).flatten()\n",
    "y1= train_labels\n",
    "    \n",
    "x2=model.predict(test_data).flatten()\n",
    "y2=test_labels\n",
    "    \n",
    "    \n",
    "train_rmse=sqrt(mean_squared_error(x1,y1))\n",
    "train_mae=np.sum(abs(x1-y1))/len(x1)\n",
    "train_r2=stats.pearsonr(x1, y1)[0]**2 \n",
    "    \n",
    "test_rmse=sqrt(mean_squared_error(x2,y2))\n",
    "test_mae=np.sum(abs(x2-y2))/len(x2)\n",
    "test_r2=stats.pearsonr(x2, y2)[0]**2\n",
    "\n",
    "print('Training')\n",
    "print('rmse: '+str(sqrt(mean_squared_error(x1,y1)))) \n",
    "print('mae: ' +str(np.sum(abs(x1-y1))/len(x1)))\n",
    "print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x1, y1)[0]**2,5)))\n",
    "          \n",
    "print('Testing')\n",
    "print('rmse: '+str(sqrt(mean_squared_error(x2,y2)))) \n",
    "print('mae: ' +str(np.sum(abs(x2-y2))/len(x2)))\n",
    "print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x2, y2)[0]**2,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:07:22.196273Z",
     "start_time": "2021-02-22T23:07:18.133356Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 260 out of 260 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 260 out of 260 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "rmse: 0.9499402876993236\n",
      "mae: 0.37010346360679613\n",
      "$\\mathregular{R^2}$=0.95276\n",
      "Testing\n",
      "rmse: 0.9812832556245693\n",
      "mae: 0.4011168532714908\n",
      "$\\mathregular{R^2}$=0.95023\n"
     ]
    }
   ],
   "source": [
    "RFR_model = RandomForestRegressor(n_estimators = 260, oob_score = True, n_jobs = -1,max_depth= 7, random_state =28,verbose=1)#,min_samples_leaf = 5)\n",
    "RFR_model.fit(X = train_data,y = train_labels)\n",
    "\n",
    "model=RFR_model\n",
    "x1 = model.predict(train_data).flatten()\n",
    "y1= train_labels\n",
    "    \n",
    "x2=model.predict(test_data).flatten()\n",
    "y2=test_labels\n",
    "    \n",
    "    \n",
    "train_rmse=sqrt(mean_squared_error(x1,y1))\n",
    "train_mae=np.sum(abs(x1-y1))/len(x1)\n",
    "train_r2=stats.pearsonr(x1, y1)[0]**2 \n",
    "    \n",
    "test_rmse=sqrt(mean_squared_error(x2,y2))\n",
    "test_mae=np.sum(abs(x2-y2))/len(x2)\n",
    "test_r2=stats.pearsonr(x2, y2)[0]**2\n",
    "\n",
    "print('Training')\n",
    "print('rmse: '+str(sqrt(mean_squared_error(x1,y1)))) \n",
    "print('mae: ' +str(np.sum(abs(x1-y1))/len(x1)))\n",
    "print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x1, y1)[0]**2,5)))\n",
    "          \n",
    "print('Testing')\n",
    "print('rmse: '+str(sqrt(mean_squared_error(x2,y2)))) \n",
    "print('mae: ' +str(np.sum(abs(x2-y2))/len(x2)))\n",
    "print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x2, y2)[0]**2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:07:49.498438Z",
     "start_time": "2021-02-22T23:07:49.429413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Paper_1/Large_Model/ML/RFR_no_NM.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(RFR_model, 'D:/Paper_1/Large_Model/ML/RFR_no_NM.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:14:10.784878Z",
     "start_time": "2021-02-21T17:24:00.664890Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [10, 12, 15],\n",
    "              'learning_rate': [0.001, 0.01, 0.1],\n",
    "              'n_estimators': [500,600, 1000],\n",
    "              'subsample': [0.6, 0.8, 0.9],\n",
    "              #'reg_alpha': [0, 0.25, 0.5, 0.75, 1],\n",
    "             # 'reg_lambda': [0.2, 0.4, 0.6, 0.8, 1]\n",
    "}\n",
    "\n",
    "xlf = xgb.XGBRegressor(max_depth=5,learning_rate=0.001,n_estimators=160,silent=True,objective='reg:squarederror',subsample=0.85,n_jobs=-1)#reg_alpha=0,reg_lambda=1)\n",
    "\n",
    "gsearch = GridSearchCV(xlf, param_grid=parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "gsearch.fit(X = train_data,y = train_labels)\n",
    "\n",
    "print(\"Best score: %0.3f\" % gsearch.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gsearch.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:12:05.953230Z",
     "start_time": "2021-02-22T23:12:01.461095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent, verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Training\n",
      "rmse: 0.8643245175463781\n",
      "mae: 0.3790505625235181\n",
      "$\\mathregular{R^2}$=0.97185\n",
      "Testing\n",
      "rmse: 0.9967369721607087\n",
      "mae: 0.43733689299588613\n",
      "$\\mathregular{R^2}$=0.96264\n"
     ]
    }
   ],
   "source": [
    "XGB_model = xgb.XGBRegressor(max_depth=7,learning_rate=0.01,n_estimators=240,silent=True,subsample=0.8,objective='reg:squarederror',verbose=1)\n",
    "XGB_model.fit(X = train_data,y = train_labels)\n",
    "\n",
    "model=XGB_model\n",
    "x1 = model.predict(train_data).flatten()\n",
    "y1= train_labels\n",
    "    \n",
    "x2=model.predict(test_data).flatten()\n",
    "y2=test_labels\n",
    "    \n",
    "    \n",
    "train_rmse=sqrt(mean_squared_error(x1,y1))\n",
    "train_mae=np.sum(abs(x1-y1))/len(x1)\n",
    "train_r2=stats.pearsonr(x1, y1)[0]**2 \n",
    "    \n",
    "test_rmse=sqrt(mean_squared_error(x2,y2))\n",
    "test_mae=np.sum(abs(x2-y2))/len(x2)\n",
    "test_r2=stats.pearsonr(x2, y2)[0]**2\n",
    "\n",
    "print('Training')\n",
    "print('rmse: '+str(sqrt(mean_squared_error(x1,y1)))) \n",
    "print('mae: ' +str(np.sum(abs(x1-y1))/len(x1)))\n",
    "print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x1, y1)[0]**2,5)))\n",
    "          \n",
    "print('Testing')\n",
    "print('rmse: '+str(sqrt(mean_squared_error(x2,y2)))) \n",
    "print('mae: ' +str(np.sum(abs(x2-y2))/len(x2)))\n",
    "print(\"$\\mathregular{R^2}$=\"+str(round(stats.pearsonr(x2, y2)[0]**2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T23:12:27.720865Z",
     "start_time": "2021-02-22T23:12:27.708818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Paper_1/Large_Model/ML/XGB_no_NM.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(XGB_model, 'D:/Paper_1/Large_Model/ML/XGB_no_NM.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
